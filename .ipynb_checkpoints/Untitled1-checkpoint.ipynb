{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd \n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "class K_Means:\n",
    "    def __init__(self, k =3, tolerance = 0.0001, max_iterations = 500):\n",
    "        self.k = k\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def fit(self, data):\n",
    "\n",
    "        self.centroids = {}\n",
    "\n",
    "        #initialize the centroids, the first 'k' elements in the dataset will be our initial centroids\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[[\"N\", \"ya\"]].values[i]\n",
    "\n",
    "        #begin iterations\n",
    "        for i in range(self.max_iterations):\n",
    "            self.classes = {}\n",
    "            for i in range(self.k):\n",
    "                self.classes[i] = []\n",
    "\n",
    "            #find the distance between the point and cluster; choose the nearest centroid\n",
    "            i = 1\n",
    "            for index, row in data.iterrows():\n",
    "                #print(\"features\", features)\n",
    "                distances = [np.linalg.norm(row[[\"N\", \"ya\"]].values - self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classes[classification].append(row)\n",
    "                i += 1\n",
    "\n",
    "            previous = dict(self.centroids)\n",
    "\n",
    "            #average the cluster datapoints to re-calculate the centroids\n",
    "            for classification in self.classes:\n",
    "                self.centroids[classification] = np.average([row[[\"N\", \"ya\"]].values for row in self.classes[classification]], axis = 0)\n",
    "\n",
    "            isOptimal = True\n",
    "\n",
    "            for centroid in self.centroids:\n",
    "\n",
    "                original_centroid = previous[centroid]\n",
    "                curr = self.centroids[centroid]\n",
    "\n",
    "                if len(original_centroid) > 0:\n",
    "                    if np.sum((curr - original_centroid)/original_centroid * 100.0) > self.tolerance:\n",
    "                        isOptimal = False\n",
    "\n",
    "            #break out of the main loop if the results are optimal, ie. the centroids don't change their positions much(more than our tolerance)\n",
    "            if isOptimal:\n",
    "                break\n",
    "\n",
    "    def pred(self, data):\n",
    "        distances = [np.linalg.norm(data[[\"N\", \"ya\"]].values - self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    df['text'] = df['text'].str.lower().replace(\"[^A-Za-z\\s]\", \"\")\n",
    "    \n",
    "    #df['text'] = df['text'].apply(lambda x: [x if x not in stopwords.words('english')])\n",
    "\n",
    "    #df['text'] = df['text'].apply(lambda x: [item for item in x if len(nltk.pos_tag(item)) > 0 and nltk.pos_tag(item)[0] in target_tags])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_noun_counts(df):\n",
    "    \n",
    "    txt = df['text'].apply(nltk.word_tokenize)\n",
    "    count = txt.apply(lambda x: 10 * len([word for word,pos in nltk.pos_tag(x) if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')])) \n",
    "    df['N'] = count \n",
    "    \n",
    "\n",
    "    count = txt.apply(lambda x: 10 * len([word for word,pos in nltk.pos_tag(x) if pos.startswith('J')]))\n",
    "    df['ADJ'] = count \n",
    "    \n",
    "    \n",
    "    df[\"sentenceLength\"] = len(txt)\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2       [limited, water, resources, are, all, challeng...\n",
      "3       [and, we, 've, invited, expert, witnesses, ,, ...\n",
      "4       [drought, is, certainly, a, critical, issue, f...\n",
      "5       [so, ,, i, appreciate, you, being, here, today...\n",
      "6       [with, that, ,, we, will, go, ahead, and, begi...\n",
      "7               [no, ,, we, 'll, get, right, into, it, .]\n",
      "8       [okay, ,, okay, ,, very, good, ., okay, ., i, ...\n",
      "9       [good, morning, ,, and, thank, you, mr., peria...\n",
      "10      [to, get, to, the, crux, of, this, discussion,...\n",
      "11      [and, we, need, to, prepare, ,, better, prepar...\n",
      "12      [it, 's, important, to, note, that, these, imp...\n",
      "13      [and, i, 'm, sure, they, can, tell, a, much, b...\n",
      "14      [doctor, lund, here, with, me, today, ,, with,...\n",
      "15      [this, has, resulted, in, a, direct, cost, to,...\n",
      "16      [there, 's, estimates, that, nearly, 30, milli...\n",
      "17      [livestock, producers, alike, have, also, expe...\n",
      "18      [and, are, the, sole, producer, of, 14, commod...\n",
      "19      [so, ,, they, are, adapting, to, remaining, su...\n",
      "20      [one, way, in, ,, which, we, can, achieve, thi...\n",
      "21      [that, is, a, reduction, of, water, to, crops,...\n",
      "22      [i, look, forward, to, hearing, today, from, d...\n",
      "23      [and, while, that, provides, a, short-term, so...\n",
      "24      [nearly, two, inches, per, month, in, some, pl...\n",
      "25      [this, makes, it, clear, that, while, the, sus...\n",
      "26      [and, as, more, private, drinking, water, well...\n",
      "27      [there, 's, an, active, decision, about, makin...\n",
      "28      [i, know, dr., mountjoy, today, will, highligh...\n",
      "29      [we, are, working, together, with, our, ongoin...\n",
      "30      [even, as, the, drought, persists, ,, the, dro...\n",
      "31      [in, addition, to, assistance, programs, ,, ou...\n",
      "                              ...                        \n",
      "3970    [i, 'm, michael, malter, ,, a, senior, partner...\n",
      "3971    [i, 've, practiced, bankruptcy, law, for, 35, ...\n",
      "3972    [i, 'm, a, certified, bankruptcy, specialist, ...\n",
      "3973    [i, 'm, here, in, very, strong, support, of, s...\n",
      "3974    [prior, to, april, 2012, ,, if, a, debtor, 's,...\n",
      "3975    [that, was, the, state, of, the, law, for, 35,...\n",
      "3976    [that, changed, in, april, 2012, with, the, 9t...\n",
      "3977    [this, change, has, worked, a, great, hardship...\n",
      "3978    [one, such, case, involved, my, clients, frank...\n",
      "3979    [the, copes, who, are, residents, of, portola,...\n",
      "3980    [frank, had, been, very, successful, in, the, ...\n",
      "3981    [additionally, ,, frank, suffered, two, stroke...\n",
      "3982    [the, businesses, failed, ,, and, because, fra...\n",
      "3983    [after, the, bankruptcy, filing, ,, frank, was...\n",
      "3984    [at, the, time, of, the, bankruptcy, filing, ,...\n",
      "3985    [they, had, an, ira, in, the, amount, of, $, 2...\n",
      "3986    [and, at, the, time, of, the, bankruptcy, fili...\n",
      "3987    [after, the, filing, ,, the, copes, fully, coo...\n",
      "3988    [the, house, was, sold, on, september, 26, ,, ...\n",
      "3989    [because, the, copes, were, over, 65, and, fra...\n",
      "3990    [they, moved, in, an, affordable, rental, home...\n",
      "3991    [the, jacobson, case, ,, which, i, earlier, re...\n",
      "3992    [the, copes, ', six, month, reinvestment, peri...\n",
      "3993    [on, april, 27, ,, the, copes, ', chapter, 7, ...\n",
      "3994    [at, that, time, only, $, 37,000, of, the, $, ...\n",
      "3995    [these, remaining, funds, were, desperately, n...\n",
      "3996    [on, july, 9th, ,, 2012, ,, the, bankruptcy, c...\n",
      "3997                  [the, court, could, have, ordered-]\n",
      "3998    [sir, ,, we, need, you, to, wrap, up, quickly, .]\n",
      "3999                           [okay, ., i, 'm, sorry, .]\n",
      "Name: text, Length: 3998, dtype: object\n",
      "2       120\n",
      "3       130\n",
      "4       100\n",
      "5       110\n",
      "6       110\n",
      "7         0\n",
      "8       220\n",
      "9       290\n",
      "10      110\n",
      "11      150\n",
      "12       80\n",
      "13      200\n",
      "14      230\n",
      "15      130\n",
      "16      190\n",
      "17      200\n",
      "18      160\n",
      "19      100\n",
      "20      120\n",
      "21      150\n",
      "22      140\n",
      "23       70\n",
      "24      150\n",
      "25      100\n",
      "26      180\n",
      "27       90\n",
      "28      130\n",
      "29      140\n",
      "30      170\n",
      "31      190\n",
      "       ... \n",
      "3970     90\n",
      "3971     60\n",
      "3972    110\n",
      "3973     30\n",
      "3974    150\n",
      "3975     30\n",
      "3976    120\n",
      "3977    100\n",
      "3978     30\n",
      "3979     50\n",
      "3980    100\n",
      "3981     10\n",
      "3982     60\n",
      "3983     40\n",
      "3984     70\n",
      "3985     50\n",
      "3986     70\n",
      "3987     70\n",
      "3988     20\n",
      "3989     40\n",
      "3990     50\n",
      "3991     30\n",
      "3992     50\n",
      "3993     60\n",
      "3994     60\n",
      "3995     40\n",
      "3996     90\n",
      "3997     10\n",
      "3998     10\n",
      "3999     10\n",
      "Name: text, Length: 3998, dtype: int64\n",
      "Housing and Community Development                           1111\n",
      "Agriculture                                                  654\n",
      "Insurance                                                    558\n",
      "Human Services                                               430\n",
      "Appropriations                                               383\n",
      "Arts, Entertainment, Sports, Tourism, and Internet Media     295\n",
      "Health                                                       278\n",
      "Governmental Organization                                    149\n",
      "Judiciary                                                    140\n",
      "Name: c_name, dtype: int64\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-4874c62fbeab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-272-4874c62fbeab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;31m#returns a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mkm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_Means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m      \u001b[0;31m# Plotting starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-269-8903cee59dd7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_centroid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moriginal_centroid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moriginal_centroid\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                         \u001b[0misOptimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(\"DigitalDemocracy/committee_utterances.tsv\", sep=\"\\t\")\n",
    "\n",
    "    df = df.iloc[2:4000]\n",
    "    \n",
    "    df = pre_processing(df)\n",
    "    df = pre_processing_noun_counts(df)\n",
    "    #print(df.head())\n",
    "    #return\n",
    "        \n",
    "    #df[\"hi\"] = df[\"text\"].str.len()\n",
    "    df[\"ya\"] = df[\"text\"].str.len()\n",
    "    \n",
    "    labels = df['c_name'].value_counts()\n",
    "    print(labels)\n",
    "    #print(df.head())\n",
    "    \n",
    "    #df = df[[\"hi\", \"ya\"]]\n",
    "    \n",
    "    \n",
    "    #dataset = df.astype(float).values.tolist()\n",
    "    X = df #returns a numpy array\n",
    "    km = K_Means(len(labels))\n",
    "    km.fit(X)\n",
    "    \n",
    "     # Plotting starts here\n",
    "    colors = 10*[\"r\", \"g\", \"c\", \"b\", \"k\"]\n",
    "\n",
    "    print(km.centroids)\n",
    "    for centroid in km.centroids:\n",
    "        plt.scatter(km.centroids[centroid][0], km.centroids[centroid][1], s = 130, marker = \"x\")\n",
    "\n",
    "    for classification in km.classes:\n",
    "        color = colors[classification]\n",
    "        for features in km.classes[classification]:\n",
    "            plt.scatter(features[0], features[1], color = color,s = 30)\n",
    "            \n",
    "            \n",
    "    purity_total_rows = len(df)\n",
    "    purity_max_sum = 0\n",
    "\n",
    "    rows = {}\n",
    "    sum_f1 = 0\n",
    "\n",
    "    print('length', len(km.classes))\n",
    "    for cluster in range(0, len(km.classes)):\n",
    "        max_label = \"\"\n",
    "        max_label_amt = 0\n",
    "        row = []\n",
    "        for label in labels.keys():\n",
    "            items_per_label = len([x for x in km.classes[cluster] if x['c_name'] == label])\n",
    "            print(items_per_label)\n",
    "            row.append(items_per_label)\n",
    "            if(items_per_label > max_label_amt):\n",
    "                max_label_amt = items_per_label\n",
    "                max_label = label\n",
    "        \n",
    "        #precision = max_label_amt / len(km.classes[cluster])\n",
    "        #recall = max_label_amt / labels[max_label]\n",
    "        purity_max_sum += max(row) #Add maximum label value present in cluster\n",
    "        print(purity_max_sum)\n",
    "        #f1 = (2 * precision * recall) / (precision + recall)\n",
    "        \n",
    "        #sum_f1 += f1\n",
    "    \n",
    "    #average_f1 = sum_f1/len(km.classes)\n",
    "\n",
    "    \n",
    "    #print(\"Average F1\", average_f1) #F1 Avg Calculation\n",
    "    print(\"Purity\", purity_max_sum/purity_total_rows) #Purity Calculation\n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
